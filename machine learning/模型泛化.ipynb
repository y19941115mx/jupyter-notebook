{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型泛化\n",
    "指的是训练的模型，对于不是训练集的输入也能给出合适的输出，该性质称为模型的泛化能力。是一个模型能否投入到生成环境中，最重要的指标。拿考试为例，模型的训练就是做练习题，做练习题的正确与否没法衡量一个学生对知识的掌握程度，只有用测验的方式，让学生做没有做过的题目，才能衡量学生的对知识的掌握的程度，模型的泛化能力好，相当于学生通过做练习题，真正学习到了有用的知识，反映模型的效果好。\n",
    "### 模型的偏差和方差\n",
    "偏差：衡量的是模型预测值偏离现实值的程度。对问题本身的假设不正确，例如：使用线性回归的模型去拟合非线性的数据，会导致模型偏差变大。表现为模型欠拟合。\n",
    "\n",
    "方差： 衡量的是模型之间的差异程度。 使用的模型过于复杂，参数过多，会导致模型的方差变大。例如：使用多项式回归时，加入过多的多项式项。表现为模型出现过拟合。\n",
    "\n",
    "总结：\n",
    "1. 有些算法天生高偏差，大多数的参数学习方法，例如线性回归，因为对数据有很强的假设。\n",
    "2. 有些算法天生高方差，大多数的非参数学习方法，例如KNN，因为不对数据做任何假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权衡偏差和方差\n",
    "偏差的问题可以通过更换更合适的模型解决，机器学习的主要挑战来自于方差，解决模型方差过大的方法有：\n",
    "1. 降低模型复杂度（更换合适的模型）\n",
    "2. 减少数据维度，降噪（PCA方法）\n",
    "3. 增加样本数（尤其对于深度学习之类的数据驱动算法）\n",
    "4. 使用交叉验证的方式(调节超参数)\n",
    "5. 模型正则化（限制参数的大小）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交叉验证\n",
    "我们在训练模型之前，通常把数据划分为训练数据和测试数据，使用训练数据来训练模型，使用测试数据来衡量模型的性能，再根据模型在数据集的表现对模型的超参数进行调整。但这种衡量标准导致一个问题，我们通过调参，得到的测试结果最好的模型，可能只是针对当前测试集效果很好。为了解决这个问题，引入了交叉验证的概念。\n",
    "\n",
    "交叉验证的概念： 把训练数据分成K份，每次训练K个模型，把K个模型的平均值作为模型验证的结果。scikit-learn库的网格搜索就是使用了这种验证的方式。\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = [{\n",
    "    'n_neighbors': [i for i in range(1,10)],\n",
    "    'weights': ['uniform'],\n",
    "     'p': [ i for i in range(1, 5)]\n",
    "},{\n",
    "     'n_neighbors': [i for i in range(1, 10)],\n",
    "    'weights':['distance'],\n",
    "    'p': [ i for i in range(1, 5)]\n",
    "}\n",
    "]\n",
    "grid_cv = GridSearchCV(knn_clf, grid_params, n_jobs=-1, verbose=2)\n",
    "grid_cv.fit(X, y) #验证模型\n",
    "\n",
    "grid_cv.best_params_ # 得到模型验证的结果\n",
    "grid_cv.best_estimator_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型正则化\n",
    "给目标函数加入正则化项，通过限制参数的大小， 解决模型过拟合问题\n",
    "在线性回归中加入模型正则化的算法有：\n",
    "1. 岭回归\n",
    "2. LASSO回归 趋向于将参数变为0，可以用来做特征选择 \n",
    "3. 弹性网（结合前两种）\n",
    "\n",
    "三个算法的区别主要为后面的正则项不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso 回归\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01) # alpha 为超参数 代表正则项的权重 这里比较大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit()\n",
    "lasso.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 岭回归\n",
    "from sklearn.linear_model import Ridge\n",
    "redge = Ridge(alpha=0.01) #alpha 为超参数 同上 这里比较小 因为后面是平方\n",
    "redge.fit()\n",
    "redge.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
